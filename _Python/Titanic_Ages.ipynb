{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda3006071fd14d4dc2ad1cee013cfc8c59",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in titanic training data\n",
    "titanic_df = pd.read_csv(\"../_Data/train.csv\")\n",
    "titanic_testing_df = pd.read_csv(\"../_Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append training and test data\n",
    "titanic_combined_df = titanic_df.append(titanic_testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the title feature for each person\n",
    "titanic_combined_df[\"Title\"] = \"\"\n",
    "\n",
    "def extract_name(name):\n",
    "    if \"Miss.\" in name:\n",
    "        return \"1\"\n",
    "    elif \"Master.\" in name:\n",
    "        return \"2\"\n",
    "    elif any(x in name for x in ['Mrs.', 'Ms.', 'Mme.', 'Lady', 'Mlle', 'Countess', 'Dona']):\n",
    "        return \"3\"\n",
    "    elif any(x in name for x in ['Mr.', 'Don.', 'Dr.', 'Rev.', 'Major', 'Sir', 'Col', 'Capt', 'Jonkheer']):\n",
    "        return \"4\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "titanic_combined_df['Title'] = titanic_combined_df.apply(lambda row: extract_name(row['Name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Genders to numbers\n",
    "titanic_combined_df = titanic_combined_df.replace('female', 0)\n",
    "titanic_combined_df = titanic_combined_df.replace('male', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cleaned dataset to work from\n",
    "titanic_cleaned_df = titanic_combined_df\n",
    "titanic_cleaned_df = titanic_cleaned_df.drop(['Cabin', 'Embarked', 'Fare', 'Name', 'Parch', 'SibSp', 'Survived', 'Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into the set without labels, and set with labels for training/validating/testing\n",
    "titanic_no_age_labels = titanic_cleaned_df[titanic_cleaned_df['Age'].isna()]\n",
    "titanic_with_age_labels = titanic_cleaned_df[titanic_cleaned_df['Age'] > 0]\n",
    "titanic_with_age_labels = titanic_with_age_labels.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the labelled dataset into features and labels\n",
    "titanic_features = titanic_with_age_labels[['Pclass', 'Sex', 'Title']]\n",
    "titanic_labels = titanic_with_age_labels[['Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and labels into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(titanic_features, titanic_labels, test_size=0.10, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'criterion': 'friedman_mse', 'min_samples_split': 8}\nBest score: 0.38656024543987605\n"
    }
   ],
   "source": [
    "# Grid Search for Decision Tree Regressor\n",
    "dtr_grid_search = tree.DecisionTreeRegressor()\n",
    "param_grid = {'criterion': ['mse', 'friedman_mse'], 'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]}\n",
    "dtr_grid_search = GridSearchCV(dtr_grid_search, param_grid, verbose=0, n_jobs=-1)\n",
    "dtr_grid_search.fit(features_train, labels_train)\n",
    "dtr_grid_search.best_params_\n",
    "print(dtr_grid_search.best_params_)\n",
    "print(f'Best score: {dtr_grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{}\nBest score: 0.3864970636073869\n"
    }
   ],
   "source": [
    "# Grid Search for Linear Regression\n",
    "lr_grid_search = tree.DecisionTreeRegressor()\n",
    "param_grid = {}\n",
    "lr_grid_search = GridSearchCV(lr_grid_search, param_grid, verbose=0, n_jobs=-1)\n",
    "lr_grid_search.fit(features_train, labels_train)\n",
    "lr_grid_search.best_params_\n",
    "print(lr_grid_search.best_params_)\n",
    "print(f'Best score: {lr_grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The score (r^2) for the testing dataset: 0.440\n"
    }
   ],
   "source": [
    "# Decision Tree Regressor for testing data\n",
    "dtr = tree.DecisionTreeRegressor(min_samples_split=8)\n",
    "dtr = dtr.fit(features_train, labels_train)\n",
    "labels_predict = dtr.predict(features_test)\n",
    "regression_score_testing_date = dtr.score(features_test, labels_test)\n",
    "print(f\"The score (r^2) for the testing dataset: {regression_score_testing_date:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the dataset that doesn't have ages\n",
    "titanic_no_age_labels_prepared = titanic_no_age_labels.drop(['PassengerId', 'Age'], axis=1)\n",
    "labels_no_age_predict = dtr.predict(titanic_no_age_labels_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe out of the age label predictions\n",
    "predicted_age_labels = pd.DataFrame(labels_no_age_predict, index=None, columns=['Age_Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the dataframe indexes so that age transers appear in correct order\n",
    "titanic_no_age_labels = titanic_no_age_labels.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the predicted age labels to the actual dataset without age labels\n",
    "titanic_no_age_labels['Age_Pred'] = predicted_age_labels['Age_Pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary columns in preparation for the join\n",
    "titanic_no_age_labels = titanic_no_age_labels.drop(['Pclass', 'Sex', 'Title', 'Age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the predicted ages over to the original imported datasets\n",
    "titanic_df_working = titanic_df\n",
    "titanic_df_working = titanic_df_working.set_index('PassengerId').join(titanic_no_age_labels.set_index('PassengerId'))\n",
    "titanic_testing_df_working = titanic_testing_df\n",
    "titanic_testing_df_working = titanic_testing_df_working.set_index('PassengerId').join(titanic_no_age_labels.set_index('PassengerId'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predicted ages into the 'Age' columns with rounding to 3 decimal points (this distinguishes the age predictions vs what was provided)\n",
    "def predicted_ages(age, age_pred):\n",
    "    if age_pred > 0:\n",
    "        return round(age_pred, 3)\n",
    "    else:\n",
    "        return age\n",
    "\n",
    "titanic_df_working['Age'] = titanic_df_working.apply(lambda row: predicted_ages(row['Age'], row['Age_Pred']), axis=1)\n",
    "titanic_testing_df_working['Age'] = titanic_testing_df_working.apply(lambda row: predicted_ages(row['Age'], row['Age_Pred']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Age_Pred' column and set to final variables\n",
    "titanic_df_final = titanic_df_working.drop(['Age_Pred'], axis=1)\n",
    "titanic_testing_df_final = titanic_testing_df_working.drop(['Age_Pred'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV files\n",
    "titanic_df_final.to_csv('train_with_ages.csv')\n",
    "titanic_testing_df_final.to_csv('test_with_ages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}